{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Crawl single site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(url): \n",
    "    res = requests.get(url) #get the website, return request.Response object\n",
    "    #print(res.status_code) #statu_code: return 200(found web), 404(not found)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    us_news_div = soup.find_all('div', re.compile('article-content'))\n",
    "    \n",
    "    title_list = []\n",
    "    for i in range(len(us_news_div)):\n",
    "        us_news_h3 = us_news_div[i].find_all('h3', recursive=False)\n",
    "        us_news_a = us_news_h3[0].find_all('a', recursive=False)\n",
    "        for index, item in enumerate(us_news_a[:]):\n",
    "            title = item.text.strip()\n",
    "            title_list.append(title)\n",
    "    return title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(title_list):\n",
    "    title_name = ''\n",
    "    url_list = []\n",
    "    pattern = re.compile('([^\\s\\w]|_)+')\n",
    "\n",
    "    for i in range(len(title_list)):\n",
    "        title = re.sub(\"[‘’]\", '', title_list[i])\n",
    "        #print(title)\n",
    "        strippedList = pattern.sub(' ', title)\n",
    "        a = strippedList.split(\" \")\n",
    "        empty_string = ''\n",
    "        if empty_string in a:\n",
    "            a = [x for x in a if x != '']\n",
    "            title_name = '-'.join(a)\n",
    "        else:\n",
    "            title_name = '-'.join(a)\n",
    "        url = 'https://www.infowars.com/'+title_name\n",
    "        url_list.append(url)        \n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(url):\n",
    "    res_content = requests.get(url) #get the website, return request.Response object\n",
    "    if(res_content.status_code == 200):\n",
    "        soup2 = BeautifulSoup(res_content.text, 'html.parser')\n",
    "        article = soup2.find_all('article')\n",
    "        content = article[0].find_all('p')\n",
    "        full_content = \"\"\n",
    "        for index, item in enumerate(content[:]):\n",
    "            content2 = item.text.strip()   \n",
    "            full_content = full_content+content2\n",
    "        return full_content\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://www.infowars.com/news/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = []\n",
    "title_list = get_title(url1)\n",
    "url_list = get_url(title_list)\n",
    "for i in range(len(title_list)):\n",
    "    content_list.append(get_content(url_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parkland Father Lauds George H.W. Bush’s Resig...</td>\n",
       "      <td>https://www.infowars.com/Parkland-Father-Lauds...</td>\n",
       "      <td>A father who lost a child during the Parkland,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FBI Raids Home Of Whistleblower On Clinton Fou...</td>\n",
       "      <td>https://www.infowars.com/FBI-Raids-Home-Of-Whi...</td>\n",
       "      <td>FBI agents raided the home of a recognized Dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ted Cruz Predicts ‘Anger And Rage’ May Lead To...</td>\n",
       "      <td>https://www.infowars.com/Ted-Cruz-Predicts-Ang...</td>\n",
       "      <td>Republican Sen. Ted Cruz told students Thursda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Former President George H.W. Bush dies at age 94</td>\n",
       "      <td>https://www.infowars.com/Former-President-Geor...</td>\n",
       "      <td>George Herbert Walker Bush, whose lone term as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google Debated Gaming Search Results to Bury C...</td>\n",
       "      <td>https://www.infowars.com/Google-Debated-Gaming...</td>\n",
       "      <td>Following Donald Trump’s election win, Google ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Parkland Father Lauds George H.W. Bush’s Resig...   \n",
       "1  FBI Raids Home Of Whistleblower On Clinton Fou...   \n",
       "2  Ted Cruz Predicts ‘Anger And Rage’ May Lead To...   \n",
       "3   Former President George H.W. Bush dies at age 94   \n",
       "4  Google Debated Gaming Search Results to Bury C...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.infowars.com/Parkland-Father-Lauds...   \n",
       "1  https://www.infowars.com/FBI-Raids-Home-Of-Whi...   \n",
       "2  https://www.infowars.com/Ted-Cruz-Predicts-Ang...   \n",
       "3  https://www.infowars.com/Former-President-Geor...   \n",
       "4  https://www.infowars.com/Google-Debated-Gaming...   \n",
       "\n",
       "                                             Content  \n",
       "0  A father who lost a child during the Parkland,...  \n",
       "1  FBI agents raided the home of a recognized Dep...  \n",
       "2  Republican Sen. Ted Cruz told students Thursda...  \n",
       "3  George Herbert Walker Bush, whose lone term as...  \n",
       "4  Following Donald Trump’s election win, Google ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe: News | URL | Content\n",
    "data = {'Title':title_list,'URL':url_list,'Content':content_list}\n",
    "df = pd.DataFrame(data)\n",
    "df = df[['Title', 'URL', 'Content']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Crawl Multiple Web Pages\n",
    "## Dataframe: News | URL | Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.infowars.com'\n",
    "res = requests.get(url) #get the website, return request.Response object\n",
    "print(res.status_code) #statu_code: return 200(found web), 404(not found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag(res, tag):   \n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    tag_li = soup.find_all('li', re.compile(tag))\n",
    "    pattern = re.compile('([^\\s\\w]|_)+')\n",
    "    tag_list = []\n",
    "    \n",
    "    for i in range(len(tag_li)):\n",
    "        tag_a = tag_li[i].find_all('a', recursive=False)\n",
    "        for index, item in enumerate(tag_a[:]):\n",
    "            tag = item.text.strip()\n",
    "            tag = pattern.sub(' ', re.sub(\"[‘’.]\", '', tag))\n",
    "            tag_list.append(tag)\n",
    "\n",
    "    return list(set(tag_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_url(title_list):\n",
    "    title_name = ''\n",
    "    url_list = []\n",
    "    pattern = re.compile('([^\\s\\w]|_)+')\n",
    "\n",
    "    for i in range(len(title_list)):\n",
    "        title = re.sub(\"[‘’]\", '', title_list[i])\n",
    "        #print(title)\n",
    "        strippedList = pattern.sub(' ', title)\n",
    "        a = strippedList.split(\" \")\n",
    "        empty_string = ''\n",
    "        if empty_string in a:\n",
    "            a = [x for x in a if x != '']\n",
    "            title_name = '-'.join(a)\n",
    "        else:\n",
    "            title_name = '-'.join(a)\n",
    "        url = 'https://www.infowars.com/category/'+title_name\n",
    "        url_list.append(url)        \n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.infowars.com/category/Science-Technology',\n",
       " 'https://www.infowars.com/category/World-News',\n",
       " 'https://www.infowars.com/category/Economy',\n",
       " 'https://www.infowars.com/category/Health',\n",
       " 'https://www.infowars.com/category/Hot-News',\n",
       " 'https://www.infowars.com/category/World-at-War',\n",
       " 'https://www.infowars.com/category/Globalism',\n",
       " 'https://www.infowars.com/category/Special-Reports',\n",
       " 'https://www.infowars.com/category/Government',\n",
       " 'https://www.infowars.com/category/US-News']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_tag = 'menu-item menu-item-type-taxonomy menu-item-object-category'\n",
    "category_url_list = get_category_url(get_tag(res, news_tag))\n",
    "category_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "#make sure the news webpages exist\n",
    "for i in range(len(category_url_list)):\n",
    "    res = requests.get(category_url_list[i]) #get the website, return request.Response object\n",
    "    print(res.status_code) #statu_code: return 200(found web), 404(not found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.infowars.com/category/Science-Technology',\n",
       " 'https://www.infowars.com/category/World-News',\n",
       " 'https://www.infowars.com/category/Economy',\n",
       " 'https://www.infowars.com/category/Health',\n",
       " 'https://www.infowars.com/category/Hot-News',\n",
       " 'https://www.infowars.com/category/World-at-War',\n",
       " 'https://www.infowars.com/category/Globalism',\n",
       " 'https://www.infowars.com/category/Special-Reports',\n",
       " 'https://www.infowars.com/category/Government',\n",
       " 'https://www.infowars.com/category/US-News']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“It Was Anarchy” As Mag 7 Quake Rocks Anchorage; Trump Promises Federal Aid',\n",
       " 'NASA announces the nine companies competing to put us back on the Moon',\n",
       " 'How many photons has the universe produced in its life?',\n",
       " 'Discovery Jeopardizes East Africa’s “cradle of mankind” Title',\n",
       " 'NASA chief shoots for constant moon presence in 10 years',\n",
       " 'U.S. Life Expectancy Is Falling – And The 2 Biggest Reasons Why Will Absolutely Stun You…',\n",
       " 'Ancient Cave Paintings Show Early Humans Understood Complex Astronomy',\n",
       " 'USA’s ‘First Biometric Terminal’ Ready to Go at Atlanta Airport',\n",
       " 'The Coldest And Snowiest November Ever? Here Is Why America’s Freakish Weather Is Only Going To Get Worse…',\n",
       " 'India Invites Other Countries for Venus Mission',\n",
       " 'Chinese Scientist Behind ‘Gene-Edited Babies’ Claims to Pause Trial After Outcry',\n",
       " 'Design, Not Accident',\n",
       " 'Like Humans, Dogs Know When They Don’t Know Enough To Make A Decision',\n",
       " 'The Truth About China’s Gene Edited Babies',\n",
       " 'Science Shocker: Adam And Eve For Real',\n",
       " 'Chinese scientist claims to have created ‘world’s first genetically edited babies’',\n",
       " 'International Space Station Infested With Mysterious & Potentially Dangerous Space Bugs',\n",
       " '200-Million-Year-Old Huge Mammal Disrupts Evolution Theory',\n",
       " 'Authorities Are Using A “Mysterious New Tool” That Can Unlock Virtually Any Cellphone',\n",
       " 'Big Gains in Quantum Tech',\n",
       " 'Science Journal: Opposing Transgender Rights Is ‘Worse’ than Curbing Science',\n",
       " 'Watch: First-Ever Plane Flies With No Moving Parts',\n",
       " 'Researchers Want to 3D-Print With Moon Dust',\n",
       " 'Gov’t Facial Biometrics Program Catches More Illegals at Airports',\n",
       " 'California Wildfires May Not Be Wildfires At All',\n",
       " 'Ultra-Bright Galaxy Feeds Black Hole by Stealing From Neighbors',\n",
       " 'Ultra-Thin Skin Uses Magnets, Acts as Bionic “Compass”',\n",
       " 'How Bezos, Cuomo and Amazon Screwed Over New York',\n",
       " 'Video: Rand Paul Warns Of Censorship Of Conservatives By Big Tech',\n",
       " 'Trump Must Stop Web Censorship To Save America And The World',\n",
       " 'National Facial Recognition Database To Use Loyalty Rewards To Identify American Shoppers',\n",
       " 'Astronomers find possible elusive star behind supernova']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_title(category_url_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_title_list = []\n",
    "for i in range(len(category_url_list)):\n",
    "    title_list = get_title(category_url_list[i])\n",
    "    news_title_list = news_title_list + title_list\n",
    "    news_title_list = list(set(news_title_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_content_list = []\n",
    "multi_page_url_list = get_url(news_title_list)\n",
    "for i in range(len(news_title_list)):\n",
    "    new_content_list.append(get_content(multi_page_url_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Massive Dow Drop Incoming – CFO Poll</td>\n",
       "      <td>https://www.infowars.com/Massive-Dow-Drop-Inco...</td>\n",
       "      <td>The Dow plunge isn’t anywhere near done.At lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington Approves Sale of 10 Apache Attack H...</td>\n",
       "      <td>https://www.infowars.com/Washington-Approves-S...</td>\n",
       "      <td>The US government has given the go-ahead to se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netanyahu to Take Over Defense Job</td>\n",
       "      <td>https://www.infowars.com/Netanyahu-to-Take-Ove...</td>\n",
       "      <td>Israeli Prime Minister Benjamin Netanyahu will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A White House Press Pass Has Nothing to do wit...</td>\n",
       "      <td>https://www.infowars.com/A-White-House-Press-P...</td>\n",
       "      <td>A federal judge today ruled the White House mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Chemical Weapon Attack Just Happened In Alep...</td>\n",
       "      <td>https://www.infowars.com/A-Chemical-Weapon-Att...</td>\n",
       "      <td>Owen Shroyer talks with guest Syrian Girl abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0               Massive Dow Drop Incoming – CFO Poll   \n",
       "1  Washington Approves Sale of 10 Apache Attack H...   \n",
       "2                 Netanyahu to Take Over Defense Job   \n",
       "3  A White House Press Pass Has Nothing to do wit...   \n",
       "4  A Chemical Weapon Attack Just Happened In Alep...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.infowars.com/Massive-Dow-Drop-Inco...   \n",
       "1  https://www.infowars.com/Washington-Approves-S...   \n",
       "2  https://www.infowars.com/Netanyahu-to-Take-Ove...   \n",
       "3  https://www.infowars.com/A-White-House-Press-P...   \n",
       "4  https://www.infowars.com/A-Chemical-Weapon-Att...   \n",
       "\n",
       "                                             Content  \n",
       "0  The Dow plunge isn’t anywhere near done.At lea...  \n",
       "1  The US government has given the go-ahead to se...  \n",
       "2  Israeli Prime Minister Benjamin Netanyahu will...  \n",
       "3  A federal judge today ruled the White House mu...  \n",
       "4  Owen Shroyer talks with guest Syrian Girl abou...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe: News | URL | Content\n",
    "data = {'Title':news_title_list,'URL':multi_page_url_list,'Content':new_content_list}\n",
    "df = pd.DataFrame(data)\n",
    "df = df[['Title', 'URL', 'Content']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Crawl Breaking News "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_breaking = 'https://www.infowars.com/breaking-news/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_title(url): \n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    us_news_div = soup.find_all('div', re.compile('articles-list'))\n",
    "\n",
    "    title_list = []\n",
    "    for i in range(len(us_news_div)):\n",
    "        us_news_a = us_news_div[i].find_all('a')\n",
    "        us_news_h3 = us_news_a[0].find_all('h3')\n",
    "\n",
    "        for index, item in enumerate(us_news_h3[:]):\n",
    "            title = item.text.strip()\n",
    "            title_list.append(title)\n",
    "\n",
    "    return title_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Socialist Losers Given The Wheel Of The Democratic Party']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_article_title(url_breaking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = []\n",
    "title_list = get_article_title(url_breaking)\n",
    "url_list = get_url(title_list)\n",
    "for i in range(len(title_list)):\n",
    "    content_list.append(get_content(url_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Socialist Losers Given The Wheel Of The Democr...</td>\n",
       "      <td>https://www.infowars.com/Socialist-Losers-Give...</td>\n",
       "      <td>It only took 24 hours for the smug Democrats a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Socialist Losers Given The Wheel Of The Democr...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.infowars.com/Socialist-Losers-Give...   \n",
       "\n",
       "                                             Content  \n",
       "0  It only took 24 hours for the smug Democrats a...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Title':title_list,'URL':url_list,'Content':content_list}\n",
    "df = pd.DataFrame(data)\n",
    "df = df[['Title', 'URL', 'Content']]\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
