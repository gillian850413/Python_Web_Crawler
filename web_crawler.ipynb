{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the News Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.infowars.com/news/'\n",
    "res = requests.get(url) #get the website, return request.Response object\n",
    "print(res.status_code) #statu_code: return 200(found web), 404(not found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h3 get title, div class: article-content\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "us_news_div = soup.find_all('div', re.compile('article-content'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = []\n",
    "for i in range(len(us_news_div)):\n",
    "    us_news_h3 = us_news_div[i].find_all('h3', recursive=False)\n",
    "    us_news_a = us_news_h3[0].find_all('a', recursive=False)\n",
    "    for index, item in enumerate(us_news_a[:]):\n",
    "        title = item.text.strip()\n",
    "        title_list.append(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe: News | URL | Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_name = ''\n",
    "url_list = []\n",
    "pattern = re.compile('([^\\s\\w]|_)+')\n",
    "\n",
    "for i in range(len(title_list)):\n",
    "    title = re.sub(\"[‘’]\", '', title_list[i])\n",
    "    #print(title)\n",
    "    strippedList = pattern.sub(' ', title)\n",
    "    a = strippedList.split(\" \")\n",
    "    empty_string = ''\n",
    "    if empty_string in a:\n",
    "        a = [x for x in a if x != '']\n",
    "        title_name = '-'.join(a)\n",
    "    else:\n",
    "        title_name = '-'.join(a)\n",
    "    url = 'https://www.infowars.com/'+title_name\n",
    "    url_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(url):\n",
    "    res_content = requests.get(url) #get the website, return request.Response object\n",
    "    if(res_content.status_code == 200):\n",
    "        soup2 = BeautifulSoup(res_content.text, 'html.parser')\n",
    "        article = soup2.find_all('article')\n",
    "        content = article[0].find_all('p')\n",
    "        full_content = \"\"\n",
    "        for index, item in enumerate(content[:]):\n",
    "            content2 = item.text.strip()   \n",
    "            full_content = full_content+content2\n",
    "        return full_content\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_list = []\n",
    "for i in range(len(title_list)):\n",
    "    content_list.append(get_content(url_list[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google Debated Gaming Search Results to Bury C...</td>\n",
       "      <td>https://www.infowars.com/Google-Debated-Gaming...</td>\n",
       "      <td>Following Donald Trump’s election win, Google ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pickup Packed With 11 Passengers Crashes After...</td>\n",
       "      <td>https://www.infowars.com/Pickup-Packed-With-11...</td>\n",
       "      <td>A high-speed chase near the U.S.-Mexico border...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ann Coulter: ‘Trump Will Be The Last Republica...</td>\n",
       "      <td>https://www.infowars.com/Ann-Coulter-Trump-Wil...</td>\n",
       "      <td>Best selling author and conservative pundit An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Broward Sheriff’s Captain Who Gave ‘Stand Down...</td>\n",
       "      <td>https://www.infowars.com/Broward-Sheriffs-Capt...</td>\n",
       "      <td>Andrew Pollack, father of Meadow Pollack who w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After Banning Alex Jones, YouTube Still Hosts ...</td>\n",
       "      <td>https://www.infowars.com/After-Banning-Alex-Jo...</td>\n",
       "      <td>YouTube is still hosting content by race hate ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Google Debated Gaming Search Results to Bury C...   \n",
       "1  Pickup Packed With 11 Passengers Crashes After...   \n",
       "2  Ann Coulter: ‘Trump Will Be The Last Republica...   \n",
       "3  Broward Sheriff’s Captain Who Gave ‘Stand Down...   \n",
       "4  After Banning Alex Jones, YouTube Still Hosts ...   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.infowars.com/Google-Debated-Gaming...   \n",
       "1  https://www.infowars.com/Pickup-Packed-With-11...   \n",
       "2  https://www.infowars.com/Ann-Coulter-Trump-Wil...   \n",
       "3  https://www.infowars.com/Broward-Sheriffs-Capt...   \n",
       "4  https://www.infowars.com/After-Banning-Alex-Jo...   \n",
       "\n",
       "                                             Content  \n",
       "0  Following Donald Trump’s election win, Google ...  \n",
       "1  A high-speed chase near the U.S.-Mexico border...  \n",
       "2  Best selling author and conservative pundit An...  \n",
       "3  Andrew Pollack, father of Meadow Pollack who w...  \n",
       "4  YouTube is still hosting content by race hate ...  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Title':title_list,'URL':url_list,'Content':content_list}\n",
    "df = pd.DataFrame(data)\n",
    "df = df[['Title', 'URL', 'Content']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
